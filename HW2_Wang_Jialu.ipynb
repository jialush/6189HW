{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_Wang_Jialu.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMDL2bH5hPkJ0f4Q+8PNOpE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jialush/6189HW/blob/master/HW2_Wang_Jialu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv8CklSHjwa7"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXKogbBT6mG6"
      },
      "source": [
        "(a)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk18iW2ylB5-"
      },
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name_a = 'keras_cifar10_trained_modela.h5'\n",
        "model_name_b = 'keras_cifar10_trained_modelb.h5'\n",
        "model_name_c = 'keras_cifar10_trained_modelc.h5'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB9_ehfDmUP9",
        "outputId": "00798978-9879-433a-ace2-19574bb70905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wykqf5clq8eZ"
      },
      "source": [
        "#simple dense neural network (sdnn), 0 hidden layers\n",
        "model_sdnn_0 = Sequential()\n",
        "model_sdnn_0.add(Flatten())\n",
        "model_sdnn_0.add(Dense(num_classes))\n",
        "model_sdnn_0.add(Activation('softmax'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv_d6NTsuYk-"
      },
      "source": [
        "#simple dense neural network (sdnn), 1 hidden layer\n",
        "model_sdnn_1 = Sequential()\n",
        "model_sdnn_1.add(Flatten())\n",
        "model_sdnn_1.add(Dense(512))\n",
        "model_sdnn_1.add(Activation('relu'))\n",
        "model_sdnn_1.add(Dropout(0.5))\n",
        "model_sdnn_1.add(Dense(num_classes))\n",
        "model_sdnn_1.add(Activation('softmax'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTB3wNbXvfJp"
      },
      "source": [
        "#simple dense neural network (sdnn), 2 hidden layer\n",
        "model_sdnn_2 = Sequential()\n",
        "model_sdnn_2.add(Flatten())\n",
        "model_sdnn_2.add(Dense(512))\n",
        "model_sdnn_2.add(Activation('relu'))\n",
        "model_sdnn_2.add(Dropout(0.5))\n",
        "model_sdnn_2.add(Dense(512))\n",
        "model_sdnn_2.add(Activation('relu'))\n",
        "model_sdnn_2.add(Dropout(0.5))\n",
        "model_sdnn_2.add(Dense(num_classes))\n",
        "model_sdnn_2.add(Activation('softmax'))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGdnKw-ovg5o"
      },
      "source": [
        "#simple dense neural network (sdnn), 3 hidden layer\n",
        "model_sdnn_3 = Sequential()\n",
        "model_sdnn_3.add(Flatten())\n",
        "model_sdnn_3.add(Dense(512))\n",
        "model_sdnn_3.add(Activation('relu'))\n",
        "model_sdnn_3.add(Dropout(0.5))\n",
        "model_sdnn_3.add(Dense(512))\n",
        "model_sdnn_3.add(Activation('relu'))\n",
        "model_sdnn_3.add(Dropout(0.5))\n",
        "model_sdnn_3.add(Dense(512))\n",
        "model_sdnn_3.add(Activation('relu'))\n",
        "model_sdnn_3.add(Dropout(0.5))\n",
        "model_sdnn_3.add(Dense(num_classes))\n",
        "model_sdnn_3.add(Activation('softmax'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOXB1QmKvhsW"
      },
      "source": [
        "#simple dense neural network (sdnn), 4 hidden layer\n",
        "model_sdnn_4 = Sequential()\n",
        "model_sdnn_4.add(Flatten())\n",
        "model_sdnn_4.add(Dense(512))\n",
        "model_sdnn_4.add(Activation('relu'))\n",
        "model_sdnn_4.add(Dropout(0.5))\n",
        "model_sdnn_4.add(Dense(512))\n",
        "model_sdnn_4.add(Activation('relu'))\n",
        "model_sdnn_4.add(Dropout(0.5))\n",
        "model_sdnn_4.add(Dense(512))\n",
        "model_sdnn_4.add(Activation('relu'))\n",
        "model_sdnn_4.add(Dropout(0.5))\n",
        "model_sdnn_4.add(Dense(512))\n",
        "model_sdnn_4.add(Activation('relu'))\n",
        "model_sdnn_4.add(Dropout(0.5))\n",
        "model_sdnn_4.add(Dense(num_classes))\n",
        "model_sdnn_4.add(Activation('softmax'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQp3JywSy2mG"
      },
      "source": [
        "# cnn\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh1bmFGrxErJ"
      },
      "source": [
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.001, decay=1e-4)\n",
        "# Let's train the model using RMSprop\n",
        "model_sdnn_0.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_sdnn_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "model_sdnn_2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "model_sdnn_3.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "model_sdnn_4.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3lvSeaUkBE3",
        "outputId": "dbdfa847-3c3b-4345-d69b-af6bfeb57779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "    model_sdnn_0.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "    model_sdnn_1.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "    model_sdnn_2.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "    model_sdnn_3.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "    model_sdnn_4.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    tic=time.time()\n",
        "    history_model=model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4,\n",
        "                        use_multiprocessing=True)\n",
        "    toc=time.time()\n",
        "    print('\\nused time:',toc-tic,'\\n')\n",
        "    \n",
        "    tic=time.time()\n",
        "    history_model_sdnn_0=model_sdnn_0.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4,\n",
        "                        use_multiprocessing=True)\n",
        "    toc=time.time()\n",
        "    print('\\nused time:',toc-tic,'\\n')\n",
        "\n",
        "    tic=time.time()\n",
        "    history_model_sdnn_1=model_sdnn_1.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4,\n",
        "                        use_multiprocessing=True)\n",
        "    toc=time.time()\n",
        "    print('\\nused time:',toc-tic,'\\n')\n",
        "\n",
        "    tic=time.time()\n",
        "    history_model_sdnn_2=model_sdnn_2.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4,\n",
        "                        use_multiprocessing=True)\n",
        "    toc=time.time()\n",
        "    print('\\nused time:',toc-tic,'\\n')\n",
        "\n",
        "    tic=time.time()\n",
        "    history_model_sdnn_3=model_sdnn_3.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4,\n",
        "                        use_multiprocessing=True)\n",
        "    toc=time.time()\n",
        "    print('\\nused time:',toc-tic,'\\n')\n",
        "\n",
        "    tic=time.time()\n",
        "    history_model_sdnn_4=model_sdnn_4.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4,\n",
        "                        use_multiprocessing=True)\n",
        "    toc=time.time()\n",
        "    print('\\nused time:',toc-tic,'\\n')\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 1.2115 - accuracy: 0.5680WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 276s 176ms/step - loss: 1.2114 - accuracy: 0.5681 - val_loss: 1.0758 - val_accuracy: 0.6277\n",
            "Epoch 2/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 1.1040 - accuracy: 0.6124WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 271s 174ms/step - loss: 1.1040 - accuracy: 0.6125 - val_loss: 0.9731 - val_accuracy: 0.6574\n",
            "Epoch 3/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 1.0406 - accuracy: 0.6346WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 279s 179ms/step - loss: 1.0405 - accuracy: 0.6346 - val_loss: 0.8831 - val_accuracy: 0.6920\n",
            "\n",
            "used time: 827.7834084033966 \n",
            "\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 1.9177 - accuracy: 0.3249WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 26s 17ms/step - loss: 1.9177 - accuracy: 0.3249 - val_loss: 1.8634 - val_accuracy: 0.3431\n",
            "Epoch 2/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 1.9012 - accuracy: 0.3274WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 25s 16ms/step - loss: 1.9014 - accuracy: 0.3274 - val_loss: 1.8270 - val_accuracy: 0.3531\n",
            "Epoch 3/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1559/1563 [============================>.] - ETA: 0s - loss: 1.8848 - accuracy: 0.3381WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 26s 16ms/step - loss: 1.8846 - accuracy: 0.3383 - val_loss: 1.8457 - val_accuracy: 0.3527\n",
            "\n",
            "used time: 77.84135317802429 \n",
            "\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 1.9624 - accuracy: 0.2814WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 54s 35ms/step - loss: 1.9623 - accuracy: 0.2814 - val_loss: 1.7995 - val_accuracy: 0.3625\n",
            "Epoch 2/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 1.9403 - accuracy: 0.2921WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 54s 35ms/step - loss: 1.9404 - accuracy: 0.2920 - val_loss: 1.7732 - val_accuracy: 0.3679\n",
            "Epoch 3/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 1.9234 - accuracy: 0.3052WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 54s 34ms/step - loss: 1.9233 - accuracy: 0.3052 - val_loss: 1.7324 - val_accuracy: 0.3806\n",
            "\n",
            "used time: 163.50549268722534 \n",
            "\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 2.0374 - accuracy: 0.2348WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 61s 39ms/step - loss: 2.0375 - accuracy: 0.2348 - val_loss: 1.9430 - val_accuracy: 0.3041\n",
            "Epoch 2/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 2.0103 - accuracy: 0.2485WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 62s 40ms/step - loss: 2.0102 - accuracy: 0.2484 - val_loss: 1.9002 - val_accuracy: 0.3428\n",
            "Epoch 3/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 1.9962 - accuracy: 0.2569WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 68s 43ms/step - loss: 1.9962 - accuracy: 0.2569 - val_loss: 1.9081 - val_accuracy: 0.3231\n",
            "\n",
            "used time: 191.3485448360443 \n",
            "\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 2.0680 - accuracy: 0.2122WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 70s 45ms/step - loss: 2.0680 - accuracy: 0.2122 - val_loss: 2.0100 - val_accuracy: 0.2986\n",
            "Epoch 2/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 2.0432 - accuracy: 0.2290WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 68s 44ms/step - loss: 2.0433 - accuracy: 0.2289 - val_loss: 2.0532 - val_accuracy: 0.2490\n",
            "Epoch 3/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 2.0312 - accuracy: 0.2349WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 68s 44ms/step - loss: 2.0312 - accuracy: 0.2349 - val_loss: 2.0611 - val_accuracy: 0.2431\n",
            "\n",
            "used time: 207.56656098365784 \n",
            "\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 2.0705 - accuracy: 0.2090WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 76s 49ms/step - loss: 2.0705 - accuracy: 0.2090 - val_loss: 2.0860 - val_accuracy: 0.2560\n",
            "Epoch 2/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 2.0485 - accuracy: 0.2208WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 79s 50ms/step - loss: 2.0485 - accuracy: 0.2207 - val_loss: 2.0660 - val_accuracy: 0.2335\n",
            "Epoch 3/3\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 2.0432 - accuracy: 0.2254WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "1563/1563 [==============================] - 77s 49ms/step - loss: 2.0432 - accuracy: 0.2254 - val_loss: 2.0754 - val_accuracy: 0.2415\n",
            "\n",
            "used time: 233.4375457763672 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byzNqseH3hqb",
        "outputId": "5d75306d-83d7-4e6f-d2a0-8bfc224841a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name_a)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b5067ed3e262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save model and weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD_ViLnn345b",
        "outputId": "9be897e4-cd28-4545-e66f-68ffd9ad23ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "epoch=range(1,(len(history_model.history['val_accuracy'])+1))\n",
        "plt.plot(epoch,history_model.history['val_accuracy'])\n",
        "plt.plot(epoch,history_model_sdnn_0.history['val_accuracy'])\n",
        "plt.plot(epoch,history_model_sdnn_1.history['val_accuracy'])\n",
        "plt.plot(epoch,history_model_sdnn_2.history['val_accuracy'])\n",
        "plt.plot(epoch,history_model_sdnn_3.history['val_accuracy'])\n",
        "plt.plot(epoch,history_model_sdnn_4.history['val_accuracy'])\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['cnn','ann0','ann1','ann2','ann3','ann4'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oocPUIsOKkU",
        "outputId": "6724ed71-fc29-4acc-8054-515391faf96d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 12s 38ms/step - loss: 0.8831 - accuracy: 0.6920\n",
            "Test loss: 0.8830771446228027\n",
            "Test accuracy: 0.6919999718666077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6_9J3ZTOBj2",
        "outputId": "f96728e4-2675-41f7-d21e-5cfda3cf8876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(model.history['val_accuracy'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-234cc4323ad1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0ylx7P-602q"
      },
      "source": [
        "(b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxu8G9j56kgH"
      },
      "source": [
        "# cnn-sigmoid\n",
        "model_sig = Sequential()\n",
        "model_sig.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model_sig.add(Activation('sigmoid'))\n",
        "model_sig.add(Conv2D(32, (3, 3)))\n",
        "model_sig.add(Activation('sigmoid'))\n",
        "model_sig.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_sig.add(Dropout(0.25))\n",
        "\n",
        "model_sig.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model_sig.add(Activation('sigmoid'))\n",
        "model_sig.add(Conv2D(64, (3, 3)))\n",
        "model_sig.add(Activation('sigmoid'))\n",
        "model_sig.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_sig.add(Dropout(0.25))\n",
        "\n",
        "model_sig.add(Flatten())\n",
        "model_sig.add(Dense(512))\n",
        "model_sig.add(Activation('sigmoid'))\n",
        "model_sig.add(Dropout(0.5))\n",
        "model_sig.add(Dense(num_classes))\n",
        "model_sig.add(Activation('softmax'))\n",
        "model_sig.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "import time\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model_sig.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    tic=time.time()\n",
        "    model_sig.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4,\n",
        "                        use_multiprocessing=True)\n",
        "    toc=time.time()\n",
        "    print('\\nused time:',toc-tic,'\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_UDwb76HPwS"
      },
      "source": [
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name_b)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTu1T8W-GCAB"
      },
      "source": [
        "plt.plot(model.history['val_accuracy'])\n",
        "plt.plot(model_sig.history['val_accuracy'])\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['cnn-relu', 'cnn-sigmoid'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiAG5kDoFRB6"
      },
      "source": [
        "Explain:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8S1D2FtGVkK"
      },
      "source": [
        "(c)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrSQRHhIH-PV"
      },
      "source": [
        "# yes dropout, yes augment cnn: model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSKI3b6HHav_"
      },
      "source": [
        "#no dropout, yes augment: model_ndya\n",
        "\n",
        "data_augmentation = True\n",
        "\n",
        "model_ndya = Sequential()\n",
        "model_ndya.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model_ndya.add(Activation('relu'))\n",
        "model_ndya.add(Conv2D(32, (3, 3)))\n",
        "model_ndya.add(Activation('relu'))\n",
        "model_ndya.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model_ndya.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model_ndya.add(Activation('relu'))\n",
        "model_ndya.add(Conv2D(64, (3, 3)))\n",
        "model_ndya.add(Activation('relu'))\n",
        "model_ndya.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model_ndya.add(Flatten())\n",
        "model_ndya.add(Dense(512))\n",
        "model_ndya.add(Activation('relu'))\n",
        "model_ndya.add(Dense(num_classes))\n",
        "model_ndya.add(Activation('softmax'))\n",
        "\n",
        "model_ndya.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "import time\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model_ndya.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    tic=time.time()\n",
        "    model_ndya.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4,\n",
        "                        use_multiprocessing=True)\n",
        "    toc=time.time()\n",
        "    print('\\nused time:',toc-tic,'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt9Ug85AHpVZ"
      },
      "source": [
        "#yes dropout, no augment: model_ndya\n",
        "\n",
        "data_augmentation = False\n",
        "\n",
        "model_ydna = Sequential()\n",
        "model_ydna.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model_ydna.add(Activation('relu'))\n",
        "model_ydna.add(Conv2D(32, (3, 3)))\n",
        "model_ydna.add(Activation('relu'))\n",
        "model_ydna.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_ydna.add(Dropout(0.25))\n",
        "\n",
        "model_ydna.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model_ydna.add(Activation('relu'))\n",
        "model_ydna.add(Conv2D(64, (3, 3)))\n",
        "model_ydna.add(Activation('relu'))\n",
        "model_ydna.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_ydna.add(Dropout(0.25))\n",
        "\n",
        "model_ydna.add(Flatten())\n",
        "model_ydna.add(Dense(512))\n",
        "model_ydna.add(Activation('relu'))\n",
        "model_ydna.add(Dropout(0.5))\n",
        "model_ydna.add(Dense(num_classes))\n",
        "model_ydna.add(Activation('softmax'))\n",
        "\n",
        "model_ydna.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "import time\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model_ydna.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    tic=time.time()\n",
        "    model_ydna.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4,\n",
        "                        use_multiprocessing=True)\n",
        "    toc=time.time()\n",
        "    print('\\nused time:',toc-tic,'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n67zCVKpHpeM"
      },
      "source": [
        "#no dropout, n augment: model_ndna\n",
        "\n",
        "data_augmentation = False\n",
        "\n",
        "model_ndna = Sequential()\n",
        "model_ndna.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model_ndna.add(Activation('relu'))\n",
        "model_ndna.add(Conv2D(32, (3, 3)))\n",
        "model_ndna.add(Activation('relu'))\n",
        "model_ndna.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model_ndna.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model_ndna.add(Activation('relu'))\n",
        "model_ndna.add(Conv2D(64, (3, 3)))\n",
        "model_ndna.add(Activation('relu'))\n",
        "model_ndna.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model_ndna.add(Flatten())\n",
        "model_ndna.add(Dense(512))\n",
        "model_ndna.add(Activation('relu'))\n",
        "model_ndna.add(Dense(num_classes))\n",
        "model_ndna.add(Activation('softmax'))\n",
        "\n",
        "model_ndna.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "import time\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model_ndna.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    tic=time.time()\n",
        "    model_ndna.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4,\n",
        "                        use_multiprocessing=True)\n",
        "    toc=time.time()\n",
        "    print('\\nused time:',toc-tic,'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6jxyVIpFRW6"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ipAhP-vGo5E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}